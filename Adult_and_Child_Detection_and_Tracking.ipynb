{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install deepsort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK9h0-DqZxrr",
        "outputId": "9175ae1a-d8cb-4033-ddb6-a9fd57541771"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepsort in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
            "Requirement already satisfied: scikit-learn==1.1.3 in /usr/local/lib/python3.10/dist-packages (from deepsort) (1.1.3)\n",
            "Requirement already satisfied: scipy==1.9.3 in /usr/local/lib/python3.10/dist-packages (from deepsort) (1.9.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->deepsort) (1.25.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->deepsort) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->deepsort) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install deep_sort_realtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfbDu9k6agCc",
        "outputId": "be42fba7-f9e5-4b24-edb2-a6947b8a244e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep_sort_realtime\n",
            "  Using cached deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.9.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (4.10.0.84)\n",
            "Using cached deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "Installing collected packages: deep_sort_realtime\n",
            "Successfully installed deep_sort_realtime-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Important Package\n"
      ],
      "metadata": {
        "id": "77yLPkLFst7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qLdXZgzVsjO-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Pre-trained Model for object detection"
      ],
      "metadata": {
        "id": "9PkHOL12dYxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "  model_url = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\"\n",
        "  model = hub.load(model_url)\n",
        "  return model"
      ],
      "metadata": {
        "id": "wIgh2yA2dYgD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objectdetection(model, image):\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  detections = model(input_tensor)\n",
        "  return detections\n",
        "\n",
        "#function to assign unique ids to detected person\n",
        "def assign_unique_ids(detected_person, unique_ids, next_id):\n",
        "  new_ids = {}\n",
        "  for person in detected_person:\n",
        "    person_tuple = tuple(person)\n",
        "    if person_tuple not in unique_ids:\n",
        "      unique_ids[person_tuple] = next_id # Assign new ID if person not in unique_ids\n",
        "      next_id += 1\n",
        "    new_ids[person_tuple] = unique_ids[person_tuple]\n",
        "  return new_ids, next_id\n",
        "\n",
        "\n",
        "#function to process videos\n",
        "def vid_process(video_path, model, output_frame_dir):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  frame_num = 0\n",
        "  unique_ids = {}\n",
        "  next_id = 1\n",
        "\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not  ret:\n",
        "      break\n",
        "    frame_num += 1\n",
        "\n",
        "    #skip some frames to reduce processing load\n",
        "    if frame_num % 10 != 0:\n",
        "      continue\n",
        "\n",
        "    # perform obj detection\n",
        "    detections = objectdetection(model, frame)\n",
        "\n",
        "    #Extract person detection\n",
        "    person_detections =[]\n",
        "    for i in range(int(detections['num_detections'][0])):\n",
        "      if detections['detection_classes'][0][i].numpy()==1:\n",
        "        ymin, xmin, ymax, xmax = detections['detection_boxes'][0][i].numpy()\n",
        "        h, w, _ = frame.shape\n",
        "        person_detections.append([xmin * w, ymin * h, xmax * w, ymax * h])\n",
        "\n",
        "    # assign unique IDs to detected persons\n",
        "    new_ids, next_id = assign_unique_ids(person_detections, unique_ids, next_id)\n",
        "\n",
        "    # Save the frames where persons are detected\n",
        "    for detection, uid in zip(person_detections, new_ids.values()):\n",
        "      x1, y1, x2, y2 = detection\n",
        "      person_image = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "      person_image_path = f'{output_frame_dir}/person_{uid}_frame_{frame_num}.jpg'\n",
        "      cv2.imwrite(person_image_path, person_image)\n",
        "  cap.release()\n",
        "  print(\"Detection and ID assignment complete.\")\n",
        "\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    video_path = r\"/content/drive/MyDrive/Computer Vision/videos/ABA Therapy - Learning about Animals.mp4\"  # Update with the correct video filename\n",
        "    output_frame_dir = r\"/content/drive/MyDrive/Computer Vision/Frames\"\n",
        "\n",
        "    # Load the TensorFlow model\n",
        "    model = load_model()\n",
        "\n",
        "    # Process the video\n",
        "    vid_process(video_path, model, output_frame_dir)\n"
      ],
      "metadata": {
        "id": "9TyoXP2aW1P9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cf0705-818d-43a4-8c34-36ac56d9224c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection and ID assignment complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, model, output_frame_dir):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_num = 0\n",
        "    unique_ids = {}\n",
        "    next_id = 1\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_num += 1\n",
        "\n",
        "        # Skip frames to reduce processing load (process every 10th frame)\n",
        "        if frame_num % 10 != 0:\n",
        "            continue\n",
        "\n",
        "        # Perform object detection\n",
        "        detections = objectdetection(model, frame)\n",
        "\n",
        "        # Extract person detections\n",
        "        person_detections = []\n",
        "        for i in range(int(detections['num_detections'][0])):\n",
        "            if detections['detection_classes'][0][i].numpy() == 1:  # Class 1 corresponds to 'person'\n",
        "                ymin, xmin, ymax, xmax = detections['detection_boxes'][0][i].numpy()\n",
        "                h, w, _ = frame.shape\n",
        "                person_detections.append([xmin * w, ymin * h, xmax * w, ymax * h])\n",
        "\n",
        "        # Assign unique IDs to detected people\n",
        "        new_ids = {}\n",
        "        for person in person_detections:\n",
        "            person_tuple = tuple(person)\n",
        "            if person_tuple not in unique_ids:\n",
        "                unique_ids[person_tuple] = next_id\n",
        "                next_id += 1\n",
        "            new_ids[person_tuple] = unique_ids[person_tuple]\n",
        "\n",
        "        # Save detected person images\n",
        "        for detection, uid in zip(person_detections, new_ids.values()):\n",
        "            x1, y1, x2, y2 = detection\n",
        "            person_image = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "            person_image_path = os.path.join(output_frame_dir, f'person_{uid}_frame_{frame_num}.jpg')\n",
        "            cv2.imwrite(person_image_path, person_image)\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Completed processing for video: {os.path.basename(video_path)}\")\n",
        "    return unique_ids"
      ],
      "metadata": {
        "id": "9Vk3ma2nuVTk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_videos(videos_dir, frames_dir, model):\n",
        "    all_unique_ids = {}\n",
        "\n",
        "    # Ensure frames directory exists\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate over all video files in the directory\n",
        "    for video_file in os.listdir(videos_dir):\n",
        "        if video_file.endswith('.mp4'):\n",
        "            video_path = os.path.join(videos_dir, video_file)\n",
        "            video_name = os.path.splitext(video_file)[0]\n",
        "\n",
        "            # Create a specific frames directory for each video\n",
        "            video_frames_dir = os.path.join(frames_dir, video_name)\n",
        "            os.makedirs(video_frames_dir, exist_ok=True)\n",
        "\n",
        "            # Process video and get unique IDs\n",
        "            unique_ids = process_video(video_path, model, video_frames_dir)\n",
        "\n",
        "            # Merge unique IDs into the aggregated dictionary\n",
        "            all_unique_ids[video_name] = unique_ids\n",
        "\n",
        "    return all_unique_ids"
      ],
      "metadata": {
        "id": "Ui1N0014vwS6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def save_to_csv(all_unique_ids, output_csv_dir):\n",
        "    os.makedirs(output_csv_dir, exist_ok=True)\n",
        "\n",
        "    for video_name, unique_ids in all_unique_ids.items():\n",
        "        csv_path = os.path.join(output_csv_dir, f\"{video_name}_detection.csv\")\n",
        "\n",
        "        # Count occurrences\n",
        "        id_counts = {}\n",
        "        for uid in unique_ids.values():\n",
        "            id_counts[uid] = id_counts.get(uid, 0) + 1\n",
        "\n",
        "        # Write to CSV\n",
        "        with open(csv_path, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['Person ID', 'Count'])\n",
        "            for uid, count in id_counts.items():\n",
        "                writer.writerow([uid, count])\n",
        "\n",
        "        print(f\"CSV file saved for {video_name} at {csv_path}\")"
      ],
      "metadata": {
        "id": "gKGnpoU0vwP3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    videos_dir = r\"/content/drive/MyDrive/Computer Vision/videos\"\n",
        "    frames_dir = r\"/content/drive/MyDrive/Computer Vision/Frames\"\n",
        "    output_csv_dir = r\"/content/drive/MyDrive/Computer Vision/CSV OUPUTS\"\n",
        "\n",
        "    # Load model\n",
        "    model = load_model()\n",
        "\n",
        "    # Process all videos and get unique IDs\n",
        "    all_unique_ids = process_all_videos(videos_dir, frames_dir, model)\n",
        "\n",
        "    # Save results to CSV files\n",
        "    save_to_csv(all_unique_ids, output_csv_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vvNd5vVvwJs",
        "outputId": "2af62b08-e5bc-469e-da62-ab2149759f7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed processing for video: Exploring the Therapeutic Playroom.mp4\n",
            "Completed processing for video: ABA Therapy_ Daniel - Communication.mp4\n",
            "Completed processing for video: Group Therapy for Autism Spectrum Disorder.mp4\n",
            "Completed processing for video: Play Therapy Session working on Feelings with Candy Land Game.mp4\n",
            "Completed processing for video: Discrete Trial Training.mp4\n",
            "Completed processing for video: ABA Therapy - Play.mp4\n",
            "Completed processing for video: Sensory Play at Home_ Proprioceptive Games.mp4\n",
            "Completed processing for video: ABA Therapy - Learning about Animals.mp4\n",
            "Completed processing for video: Matching.mp4\n",
            "Completed processing for video: videoplayback.mp4\n",
            "Completed processing for video: Preference Assessment with Toys_ Multiple Stimulus without Replacement (MSWO).mp4\n",
            "Completed processing for video: How to Do Play Therapy _ Building a Growth Mindset Role Play.mp4\n",
            "Completed processing for video: MASS TRIAL (Gross motor imitation).mp4\n",
            "Completed processing for video: Augmentative and Alternative Communication AAC.mp4\n",
            "Completed processing for video: Jan 5 SonRise Mom part 1.mp4\n",
            "Completed processing for video: ABA Therapy - Social Engagement.mp4\n",
            "Completed processing for video: Incidental Teaching.mp4\n",
            "Completed processing for video: Autism (Moderate - Severe) and ABA - Training Session.mp4\n",
            "Completed processing for video: Natural Environment Teaching (NET).mp4\n",
            "Completed processing for video: Speech Therapy Training Session- Moderate to Severe Autism.mp4\n",
            "CSV file saved for Exploring the Therapeutic Playroom at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Exploring the Therapeutic Playroom_detection.csv\n",
            "CSV file saved for ABA Therapy_ Daniel - Communication at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/ABA Therapy_ Daniel - Communication_detection.csv\n",
            "CSV file saved for Group Therapy for Autism Spectrum Disorder at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Group Therapy for Autism Spectrum Disorder_detection.csv\n",
            "CSV file saved for Play Therapy Session working on Feelings with Candy Land Game at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Play Therapy Session working on Feelings with Candy Land Game_detection.csv\n",
            "CSV file saved for Discrete Trial Training at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Discrete Trial Training_detection.csv\n",
            "CSV file saved for ABA Therapy - Play at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/ABA Therapy - Play_detection.csv\n",
            "CSV file saved for Sensory Play at Home_ Proprioceptive Games at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Sensory Play at Home_ Proprioceptive Games_detection.csv\n",
            "CSV file saved for ABA Therapy - Learning about Animals at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/ABA Therapy - Learning about Animals_detection.csv\n",
            "CSV file saved for Matching at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Matching_detection.csv\n",
            "CSV file saved for videoplayback at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/videoplayback_detection.csv\n",
            "CSV file saved for Preference Assessment with Toys_ Multiple Stimulus without Replacement (MSWO) at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Preference Assessment with Toys_ Multiple Stimulus without Replacement (MSWO)_detection.csv\n",
            "CSV file saved for How to Do Play Therapy _ Building a Growth Mindset Role Play at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/How to Do Play Therapy _ Building a Growth Mindset Role Play_detection.csv\n",
            "CSV file saved for MASS TRIAL (Gross motor imitation) at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/MASS TRIAL (Gross motor imitation)_detection.csv\n",
            "CSV file saved for Augmentative and Alternative Communication AAC at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Augmentative and Alternative Communication AAC_detection.csv\n",
            "CSV file saved for Jan 5 SonRise Mom part 1 at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Jan 5 SonRise Mom part 1_detection.csv\n",
            "CSV file saved for ABA Therapy - Social Engagement at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/ABA Therapy - Social Engagement_detection.csv\n",
            "CSV file saved for Incidental Teaching at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Incidental Teaching_detection.csv\n",
            "CSV file saved for Autism (Moderate - Severe) and ABA - Training Session at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Autism (Moderate - Severe) and ABA - Training Session_detection.csv\n",
            "CSV file saved for Natural Environment Teaching (NET) at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Natural Environment Teaching (NET)_detection.csv\n",
            "CSV file saved for Speech Therapy Training Session- Moderate to Severe Autism at /content/drive/MyDrive/Computer Vision/CSV OUPUTS/Speech Therapy Training Session- Moderate to Severe Autism_detection.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, model, output_frame_dir, video_number):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  frame_num = 0\n",
        "  unique_ids = {}\n",
        "  next_id = 1\n",
        "  video_data = []\n",
        "\n",
        "\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    frame_num += 1\n",
        "\n",
        "    # Skip frames to reduce processing load\n",
        "    if frame_num % 10 != 0:\n",
        "      continue\n",
        "    detections = objectdetection(model, frame)\n",
        "\n",
        "    person_detections = []\n",
        "    for i in range(int(detections['num_detections'][0])):\n",
        "      if detections['detection_classes'][0][i].numpy() == 1:\n",
        "        ymin, xmin, ymax, xmax = detections['detection_boxes'][0][i].numpy()\n",
        "        h, w, _ = frame.shape\n",
        "        person_detections.append([xmin * w, ymin * h, xmax * w, ymax * h])\n",
        "\n",
        "    new_ids, next_id = assign_unique_ids(person_detections, unique_ids, next_id)\n",
        "\n",
        "    for detection, uid in zip(person_detections, new_ids.values()):\n",
        "      x1, y1, x2, y2 = detection\n",
        "      person_image = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "      person_image_path = os.path.join(output_frame_dir, f'person_{uid}_frame_{frame_num}.jpg')\n",
        "      cv2.imwrite(person_image_path, person_image)\n",
        "      # Collect data for CSV\n",
        "      video_data.append({'Person ID': uid,'Image Path': person_image_path,'Frame Number': frame_num,'Video Number': video_number,'Count': 1 })  # This is just a placeholder; it will be counted later\n",
        "\n",
        "  cap.release()\n",
        "  return video_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LPjdQ3Hew7lC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_videos(videos_dir, frames_dir, model):\n",
        "    all_video_data = []\n",
        "\n",
        "    for video_number, video_file in enumerate(os.listdir(videos_dir), start=1):\n",
        "        video_path = os.path.join(videos_dir, video_file)\n",
        "        video_frames_dir = os.path.join(frames_dir, f\"video_{video_number}_frames\")\n",
        "        os.makedirs(video_frames_dir, exist_ok=True)\n",
        "\n",
        "        # Process video and collect data\n",
        "        video_data = process_video(video_path, model, video_frames_dir, video_number)\n",
        "\n",
        "        # Merge video data into the aggregated list\n",
        "        all_video_data.extend(video_data)\n",
        "\n",
        "    return all_video_data"
      ],
      "metadata": {
        "id": "xIbBNocYzPds"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_csv(all_video_data, output_csv_path):\n",
        "    # Create a dictionary to count occurrences of each Person ID\n",
        "    id_counts = {}\n",
        "    for data in all_video_data:\n",
        "        uid = data[\"Person ID\"]\n",
        "        id_counts[uid] = id_counts.get(uid, 0) + 1\n",
        "\n",
        "    # Add count information to each entry\n",
        "    for data in all_video_data:\n",
        "        uid = data[\"Person ID\"]\n",
        "        data[\"Count\"] = id_counts[uid]\n",
        "\n",
        "    # Write all data to a single CSV file\n",
        "    with open(output_csv_path, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=[\"Person ID\", \"Image Path\", \"Frame Number\", \"Video Number\", \"Count\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(all_video_data)\n",
        "\n",
        "    print(f\"CSV file saved at {output_csv_path}\")"
      ],
      "metadata": {
        "id": "SbZUmHvbzX4Y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from part2 import load_model  # Ensure part2.py has these functions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    videos_dir = r'/content/drive/MyDrive/Computer Vision/videos'\n",
        "    frames_dir = r'/content/drive/MyDrive/Computer Vision/Frames'\n",
        "    output_csv_path = r'/content/drive/MyDrive/Computer Vision/CSV OUPUTS'\n",
        "\n",
        "    # Load model\n",
        "    model = load_model()\n",
        "\n",
        "    # Process all videos and collect data\n",
        "    all_video_data = process_all_videos(videos_dir, frames_dir, model)\n",
        "\n",
        "    # Save results to a single CSV file\n",
        "    save_to_csv(all_video_data, output_csv_path)"
      ],
      "metadata": {
        "id": "v6QOLdTfzepg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}